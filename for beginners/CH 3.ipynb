{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모든 라이브러리 임포트\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "# CORA 데이터셋 로드\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# torch_geometric의 데이터를 NetworkX 그래프로 변환\n",
    "edge_index = data.edge_index\n",
    "edges = edge_index.t().numpy()\n",
    "G = nx.from_edgelist(edges, create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_geometric의 데이터를 NetworkX 그래프로 변환\n",
    "edge_index = data.edge_index\n",
    "edges = edge_index.t().numpy()\n",
    "graph_nx = nx.from_edgelist(edges, create_using=nx.Graph())\n",
    "\n",
    "# 중심 노드를 선택 (여기서는 0을 선택)\n",
    "center_nodes = [0]\n",
    "\n",
    "# 모든 이웃 노드를 저장할 리스트 초기화\n",
    "all_neighbors = []\n",
    "\n",
    "# 중심 노드들의 모든 이웃 노드를 all_neighbors에 추가\n",
    "for selected_node in center_nodes:\n",
    "    neighbors = list(graph_nx.neighbors(selected_node))\n",
    "    all_neighbors += neighbors\n",
    "\n",
    "# 중심 노드들도 all_neighbors에 추가\n",
    "all_neighbors += center_nodes\n",
    "\n",
    "# all_neighbors에 포함된 모든 노드들만으로 구성된 subgraph를 추출\n",
    "subgraph_nx1 = graph_nx.subgraph(all_neighbors)\n",
    "\n",
    "# 그래프 그리기\n",
    "pos = nx.spring_layout(subgraph_nx1, seed=42)  # Spring layout 사용\n",
    "nx.draw(subgraph_nx1, pos, with_labels=True, node_color=\"skyblue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_geometric의 데이터를 NetworkX 그래프로 변환\n",
    "edge_index = data.edge_index\n",
    "edges = edge_index.t().numpy()\n",
    "graph_nx = nx.from_edgelist(edges, create_using=nx.Graph())\n",
    "\n",
    "# 중심 노드를 선택 (여기서는 1666을 선택)\n",
    "center_nodes = [1666]\n",
    "\n",
    "# 모든 이웃 노드를 저장할 리스트 초기화\n",
    "all_neighbors = []\n",
    "\n",
    "# 중심 노드들의 모든 이웃 노드를 all_neighbors에 추가\n",
    "for selected_node in center_nodes:\n",
    "    neighbors = list(graph_nx.neighbors(selected_node))\n",
    "    all_neighbors += neighbors\n",
    "\n",
    "    # 이웃의 이웃(1차 이웃)도 all_neighbors에 추가\n",
    "    for neighbor in neighbors:\n",
    "        neighbors_of_neighbor = list(graph_nx.neighbors(neighbor))\n",
    "        all_neighbors += neighbors_of_neighbor\n",
    "\n",
    "# 중심 노드들도 all_neighbors에 추가\n",
    "all_neighbors += center_nodes\n",
    "\n",
    "# 중복을 제거하기 위해 all_neighbors를 set로 변환 후 다시 list로 변환\n",
    "all_neighbors = list(set(all_neighbors))\n",
    "\n",
    "# all_neighbors에 포함된 모든 노드들만으로 구성된 subgraph를 추출\n",
    "subgraph_nx2 = graph_nx.subgraph(all_neighbors)\n",
    "\n",
    "# 그래프 그리기\n",
    "pos = nx.spring_layout(subgraph_nx2, seed=42)  # Spring layout 사용\n",
    "nx.draw(subgraph_nx2, pos, with_labels=True, node_color=\"skyblue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biased random walk 코드 \n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def biased_random_walk(G, start_node, walk_length, p=1, q=1):\n",
    "    walk = [start_node]\n",
    "\n",
    "    while len(walk) < walk_length:\n",
    "        cur_node = walk[-1]\n",
    "        cur_neighbors = list(G.neighbors(cur_node))\n",
    "\n",
    "        if len(cur_neighbors) > 0:\n",
    "            if len(walk) == 1:\n",
    "                walk.append(random.choice(cur_neighbors))\n",
    "            else:\n",
    "                prev_node = walk[-2]\n",
    "\n",
    "                probability = []\n",
    "                for neighbor in cur_neighbors:\n",
    "                    if neighbor == prev_node:\n",
    "                        # Return parameter\n",
    "                        probability.append(1/p)\n",
    "                    elif G.has_edge(neighbor, prev_node):\n",
    "                        # Stay parameter\n",
    "                        probability.append(1)\n",
    "                    else:\n",
    "                        # In-out parameter\n",
    "                        probability.append(1/q)\n",
    "\n",
    "                probability = np.array(probability)\n",
    "                probability = probability / probability.sum()  # normalize\n",
    "\n",
    "                next_node = np.random.choice(cur_neighbors, p=probability)\n",
    "                walk.append(next_node)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_walks(G, num_walks, walk_length, p=1, q=1):\n",
    "    walks = []\n",
    "    nodes = list(G.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.shuffle(nodes)  # to ensure randomness\n",
    "        for node in nodes:\n",
    "            walk_from_node = biased_random_walk(G, node, walk_length, p, q)\n",
    "            walks.append(walk_from_node)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_walks(subgraph_nx2, 2, 8, p=0.8, q=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Walk 생성\n",
    "walks = generate_walks(G, num_walks=10, walk_length=20, p=9, q=1)\n",
    "\n",
    "# String 형태로 변환 (Word2Vec 입력을 위해)\n",
    "walks = [[str(node) for node in walk] for walk in walks]\n",
    "\n",
    "# Word2Vec 학습\n",
    "model = Word2Vec(walks, vector_size=128, window=5, min_count=0,  hs=1, sg=1, workers=4, epochs=10)\n",
    "\n",
    "# 노드 임베딩 추출\n",
    "embeddings = np.array([model.wv.get_vector(str(i)) for i in range(data.num_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 각 노드는 128차원의 vector 를 가지게 됩니다.\n",
    "node_id = '2'  # 노드 한 개를 살펴볼까요?\n",
    "vector = model.wv[node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블이 있는 노드만 선택\n",
    "labels = data.y.numpy()\n",
    "idx_train = data.train_mask.numpy()\n",
    "idx_test = data.test_mask.numpy()\n",
    "\n",
    "X_train, y_train = embeddings[idx_train], labels[idx_train]\n",
    "X_test, y_test = embeddings[idx_test], labels[idx_test]\n",
    "\n",
    "# 랜덤 포레스트 분류기 학습\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "rf_best = RandomForestClassifier(n_estimators=study.best_params['n_estimators'], \n",
    "                                 max_depth=study.best_params['max_depth'], \n",
    "                                 random_state=42)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_best.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
